Lim-Plugin-Orr - OpenDNSSEC Redundancy Robot

ABOUT

Orr can be configured to manage DNS, OpenDNSSEC and SoftHSM plugins in various
ways to create a redundant DNSSEC system. For example you can configure Orr to
setup a backup/failover system or make a signing cluster that will load balance
the work.

For available RPC calls and CLI commands please see:

	perldoc Lim::Plugin::Orr

TERMINOLOGY

A lot of the terminology comes from clustering and HA solutions but their
meaning might differ slightly so it is important to have that in mind when
reading the descriptions.

ARCHITECTURE

Here is a brief high level description of Orr and the parts within. Even if it
can seem like a lot of different parts within Orr please note that because of
how Lim and Orr is built the software can run on the same nodes as all the rest
of the software.

  +------------------------------------------------------------+
  |  QUORUM                                                    |
  |  (Orr)                                                     |
  | +--------------------------------------------------------+ |
  | |  CLUSTER                                               | |
  | | +--------------+   +--------------+   +--------------+ | |
  | | | NODE         |   | NODE         |   | NODE         | | |
  | | | (OpenDNSSEC) |   | (OpenDNSSEC) |   | (OpenDNSSEC) | | |
  | | | (SoftHSM)    |   | (SoftHSM)    |   | (SoftHSM)    | | |
  | | +--------------+   +--------------+   +--------------+ | |
  | +--------------------------------------------------------+ |
  +------------------------------------------------------------+

  QUORUM
    The controlling element of Orr, this is Orr itself where all the logic
    resides.
    Future version will have the ability to have multiple Orr instances for
    redundancy of the controlling element itself and that will be based on the
    Quorum Cluster ideas.

  CLUSTER
    A set of non-connected nodes that are defined to process a set of zones.
    This differ from the definition of Computer Cluster in the sense that they
    are not connected to each other, all connections are made from the QUORUM.

  NODE
    The computer/server that has the software needed to process zones.

These are the Perl components within Orr and a description on what they do.

  Lim::Plugin::Orr::Server
    The main RPC component, it starts ClusterManagers and manage the database
    containing all configurations.

  Lim::Plugin::Orr::Server::DB
    The main database layer, it handles the database connection, creation
    and upgrade.

  Lim::Plugin::Orr::Server::NodeWatcher
    The main node logic component, it starts watchers to manage the nodes and
    synchronize data between them. Used mainly by the ClusterManager.

  Lim::Plugin::Orr::Server::Node
    A node communication component, it simplifies communication with all
    the different plugins on the nodes. Used mainly by the NodeWatcher.

  Lim::Plugin::Orr::Server::ClusterManager
    The main cluster logic component, it will feed the NodeWatcher what it
    needs to do with the nodes.

  Lim::Plugin::Orr::Server::ZoneInput
    Component to gather the zone data/content from other external sources.

QOURUM MODES

QOURUM STATES

CLUSTER MODES

  BACKUP
    A cluster setup of 2 or more nodes, one PRIMARY and one or more SECONDARY,
    where the zone information is processed on all nodes.
    If the PRIMARY node fails, a manual action must be taken to switch to a
    SECONDARY node and in so making it the new PRIMARY.

  FAILOVER
    A cluster setup identical to BACKUP in almost every aspect.
    The only difference is that if the PRIMARY node fails, a automatic action is
    taken to switch to a SECONDARY node and making it the new PRIMARY.

  BALANCE
    A cluster setup with the recommendation of 3 or more nodes, if you only have
    2 nodes then its better to pick BACKUP or FAILOVER mode, where the zone
    information processing is balanced out over all nodes essentially creating
    virtual FAILOVER sub-clusters per zone within the cluster.
    This works by configuring a ratio of the total nodes to use for each zones
    virtual sub-cluster.
    If a node fails, all zones using that node as a PRIMARY will automatically
    switch to one of their SECONDARY node and zones using it as a SECONDARY will
    balance out across the available nodes and add a new SECONDARY.

CLUSTER STATES

  (RE)INITIALIZING
    The first state of a cluster and it happens when you first start a cluster,
    when a configuration change has been made on a cluster, when a cluster is
    recovering from DEGRADED state or brought back from a FAILURE/DISABLED
    state.
    For example this state will (re)initialize all configuration on all nodes,
    check for updated zone content and push that out.

  OPERATIONAL
    This is the state when everything is up and running as it should. It will
    continuously check for zone content updates, push that out if there are
    updates, manager ZSK/KSK synchronization/rollovers and push signed zone
    contents to configured outputs.

  DEGRADED
    This state is much like OPERATIONAL but part of the cluster is not working
    as it should but enough is working to continue. This can happen if a node
    can't be reached or is failing.

  FAILURE
    This is a serious and fatal state, something happened so that the cluster
    can not continue and has stopped all processing.
    User intervention is needed at this state since the cluster can not repair
    it self.

  DISALBED
    This indicates that the cluster is disabled.
    Can only be set through manual actions.

NODE MODES

  PRIMARY
    The primary node, considered as master. There SHOULD only be one.

  SECONDARY
    The secondary node, considered as slave/backup. There SHOULD at least be
    one.

NODE STATES

  UNKNOWN
    This is the first state of a node before anything is known about the node.

  OFFLINE
    Indicates that the node is not online.

  ONLINE
    Indicates that the node is online and operational.

  FAILURE
    Indicates that the node has failed and all processing for this node has
    stopped.
    User intervention is needed at this state.

  STANDBY
    Indicates that a node has been in OFFLINE or FAILURE state but is now
    reachable again but has not been included back into the cluster or is just
    standing by for redundancy in case another node fails.

  DISABLED
    Indicates that the node is disabled and will not be used in the cluster.
    Can only be set through manual actions.

INSTALLATION

To install this module, run the following commands:

	perl Makefile.PL
	make
	make test
	make install

SUPPORT AND DOCUMENTATION

After installing, you can find documentation for this module with the
perldoc command.

    perldoc Lim::Plugin::Orr

You can also look for information at:

    Issue tracker (report bugs here)
        http://github.com/jelu/lim-plugin-orr/issues

    GIT repository
        http://github.com/jelu/lim-plugin-orr


LICENSE AND COPYRIGHT

Copyright (C) 2013 Jerry Lundstr√∂m

This program is free software; you can redistribute it and/or modify it
under the terms of either: the GNU General Public License as published
by the Free Software Foundation; or the Artistic License.

See http://dev.perl.org/licenses/ for more information.

